# ============================================================================
# THE UNIFIED HEALTH PLATFORM - UNIFIED CI/CD PIPELINE
# ============================================================================
#
# This single workflow consolidates ALL previously separate workflows into
# one unified, modular pipeline. It handles:
#
# 1. Code Quality & Linting
# 2. Unit & Integration Testing
# 3. Security Scanning (SAST, dependency audit, secrets, containers, IaC)
# 4. Docker Image Building & ECR Push
# 5. Terraform Infrastructure Management
# 6. Environment Deployments (dev, staging, production)
# 7. Performance Audits (Lighthouse)
# 8. SBOM Generation
# 9. Drift Detection
#
# MERGED WORKFLOWS:
# - ci-tests.yml
# - security-check.yml
# - web-frontend-deploy.yml
# - aws-provider-check.yml
# - lighthouse-ci.yml
# - sbom-generation.yml
# - terraform-aws.yml
# - terraform-dev-prod-gated.yml
# - scheduled-production-deploy.yml
# - terraform-drift-check.yml
# - test-actions.yml
#
# ============================================================================

name: Unified Pipeline

on:
  # Pull request triggers: validation, tests, and scans only
  pull_request:
    branches:
      - main
      - develop
    types:
      - opened
      - synchronize
      - reopened

  # Push triggers: full pipeline
  push:
    branches:
      - main
      - develop
      - "release/**"

  # Manual trigger with environment selection
  workflow_dispatch:
    inputs:
      environment:
        description: "Target environment for deployment"
        required: false
        type: choice
        default: "none"
        options:
          - none
          - dev
          - staging
          - production
      terraform_action:
        description: "Terraform action (if deploying infrastructure)"
        required: false
        type: choice
        default: "plan"
        options:
          - plan
          - apply
      skip_tests:
        description: "Skip test suite (NOT recommended for production)"
        required: false
        type: boolean
        default: false
      dry_run:
        description: "Dry run mode (no actual deployments)"
        required: false
        type: boolean
        default: false
      run_sbom:
        description: "Generate SBOM"
        required: false
        type: boolean
        default: false
      run_drift_check:
        description: "Run infrastructure drift check"
        required: false
        type: boolean
        default: false
      run_lighthouse:
        description: "Run Lighthouse performance audit"
        required: false
        type: boolean
        default: false

  # Release triggers for SBOM generation
  release:
    types: [published]

  # Scheduled triggers
  schedule:
    # Drift check: every 6 hours
    - cron: "0 */6 * * *"
    # Production deployment window: Tuesday 9pm CST (3am UTC Wednesday)
    - cron: "0 3 * * 3"

# ============================================================================
# ENVIRONMENT VARIABLES
# ============================================================================
env:
  NODE_VERSION: "22"
  TF_VERSION: "1.6.0"
  AWS_REGION: "us-east-1"
  TF_WORKING_DIR: "infrastructure/terraform-aws"

# ============================================================================
# PERMISSIONS (Least Privilege)
# ============================================================================
permissions:
  id-token: write
  contents: read
  pull-requests: write
  security-events: write
  issues: write
  actions: read
  packages: write

# ============================================================================
# CONCURRENCY CONTROL
# ============================================================================
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: ${{ github.event_name == 'pull_request' }}

# ============================================================================
# JOBS
# ============================================================================
jobs:
  # ==========================================================================
  # STAGE 1: SETUP & PREREQUISITES
  # ==========================================================================
  setup:
    name: Setup & Prerequisites
    runs-on: ubuntu-latest
    outputs:
      cache-key: ${{ steps.cache-key.outputs.key }}
      should_run_tests: ${{ steps.determine.outputs.run_tests }}
      should_run_security: ${{ steps.determine.outputs.run_security }}
      should_run_terraform: ${{ steps.determine.outputs.run_terraform }}
      should_run_deploy: ${{ steps.determine.outputs.run_deploy }}
      should_run_lighthouse: ${{ steps.determine.outputs.run_lighthouse }}
      should_run_sbom: ${{ steps.determine.outputs.run_sbom }}
      should_run_drift: ${{ steps.determine.outputs.run_drift }}
      target_environment: ${{ steps.determine.outputs.target_env }}
      commit_sha: ${{ steps.meta.outputs.sha }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Generate metadata
        id: meta
        run: |
          echo "sha=${{ github.sha }}" >> $GITHUB_OUTPUT
          echo "short_sha=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT
          echo "timestamp=$(date -u +%Y%m%d%H%M%S)" >> $GITHUB_OUTPUT

      - name: Generate cache key
        id: cache-key
        run: echo "key=${{ runner.os }}-pnpm-${{ hashFiles('**/pnpm-lock.yaml') }}" >> $GITHUB_OUTPUT

      - name: Determine what to run
        id: determine
        run: |
          EVENT="${{ github.event_name }}"
          REF="${{ github.ref }}"

          # Defaults
          RUN_TESTS="true"
          RUN_SECURITY="true"
          RUN_TERRAFORM="false"
          RUN_DEPLOY="false"
          RUN_LIGHTHOUSE="false"
          RUN_SBOM="false"
          RUN_DRIFT="false"
          TARGET_ENV="none"

          # Pull Request: validation only
          if [ "$EVENT" == "pull_request" ]; then
            RUN_TESTS="true"
            RUN_SECURITY="true"
            RUN_TERRAFORM="true"  # Plan only
            # Run Lighthouse on PRs by default for performance regression detection
            RUN_LIGHTHOUSE="true"
          fi

          # Push to main: full pipeline including SBOM for compliance
          if [ "$EVENT" == "push" ] && [ "$REF" == "refs/heads/main" ]; then
            RUN_TESTS="true"
            RUN_SECURITY="true"
            RUN_TERRAFORM="true"
            RUN_DEPLOY="true"
            RUN_SBOM="true"  # Generate SBOM for security/compliance on main branch builds
            # Run Lighthouse on main branch merges for continuous performance monitoring
            RUN_LIGHTHOUSE="true"
            TARGET_ENV="dev"
          fi

          # Push to release branches: generate SBOM for compliance
          if [ "$EVENT" == "push" ] && [[ "$REF" == refs/heads/release/* ]]; then
            RUN_SBOM="true"
          fi

          # Release: generate SBOM
          if [ "$EVENT" == "release" ]; then
            RUN_SBOM="true"
          fi

          # Scheduled: drift check or production deploy
          # Use github.event.schedule to reliably distinguish between cron triggers
          # This is more reliable than checking the current hour, which can vary due to execution delays
          if [ "$EVENT" == "schedule" ]; then
            CRON_EXPR="${{ github.event.schedule }}"
            # Production deploy window: Wednesday 3am UTC (cron: 0 3 * * 3)
            if [ "$CRON_EXPR" == "0 3 * * 3" ]; then
              RUN_TESTS="true"
              RUN_SECURITY="true"
              RUN_DEPLOY="true"
              TARGET_ENV="production"
            else
              # Drift check: every 6 hours (cron: 0 */6 * * *)
              # This runs at 00:00, 06:00, 12:00, 18:00 UTC to detect infrastructure drift
              RUN_DRIFT="true"
            fi
          fi

          # Manual dispatch: respect inputs
          if [ "$EVENT" == "workflow_dispatch" ]; then
            RUN_TESTS="${{ github.event.inputs.skip_tests != 'true' }}"
            RUN_SECURITY="true"
            RUN_SBOM="${{ github.event.inputs.run_sbom }}"
            RUN_DRIFT="${{ github.event.inputs.run_drift_check }}"
            RUN_LIGHTHOUSE="${{ github.event.inputs.run_lighthouse }}"

            if [ "${{ github.event.inputs.environment }}" != "none" ]; then
              RUN_TERRAFORM="true"
              RUN_DEPLOY="true"
              TARGET_ENV="${{ github.event.inputs.environment }}"
            fi
          fi

          echo "run_tests=$RUN_TESTS" >> $GITHUB_OUTPUT
          echo "run_security=$RUN_SECURITY" >> $GITHUB_OUTPUT
          echo "run_terraform=$RUN_TERRAFORM" >> $GITHUB_OUTPUT
          echo "run_deploy=$RUN_DEPLOY" >> $GITHUB_OUTPUT
          echo "run_lighthouse=$RUN_LIGHTHOUSE" >> $GITHUB_OUTPUT
          echo "run_sbom=$RUN_SBOM" >> $GITHUB_OUTPUT
          echo "run_drift=$RUN_DRIFT" >> $GITHUB_OUTPUT
          echo "target_env=$TARGET_ENV" >> $GITHUB_OUTPUT

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Get pnpm store directory
        id: pnpm-cache
        shell: bash
        run: echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_OUTPUT

      - name: Setup pnpm cache
        uses: actions/cache@v4
        with:
          path: ${{ steps.pnpm-cache.outputs.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

  # ==========================================================================
  # STAGE 2: CODE QUALITY
  # ==========================================================================
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    needs: setup

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Restore pnpm cache
        uses: actions/cache@v4
        with:
          path: ~/.local/share/pnpm/store
          key: ${{ needs.setup.outputs.cache-key }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Check branding consistency
        run: |
          echo "Checking for disallowed branding patterns..."
          # Note: Patterns check for incorrect branding variations
          # - "UnifiedHealthcare" or "Unified Healthcare" are wrong (it's "Unified Health")
          # - "unified-health.com" is wrong (it's "unifiedhealth.com" without hyphen)
          # Domain check removed as legitimate patterns like theunifiedhealth.com exist
          DISALLOWED_PATTERNS=(
            "UnifiedHealthcare"
            "Unified Healthcare"
            "unified-health\.com"
          )
          EXCLUDE_PATTERNS="--exclude-dir=node_modules --exclude-dir=.git --exclude-dir=dist --exclude-dir=.pnpm --exclude-dir=.next --exclude-dir=coverage --exclude-dir=.turbo --exclude=*.lock --exclude=pnpm-lock.yaml"
          WHITELIST_FILES="branding.ts|branding.d.ts|app.json|package.json|\.env|Dockerfile|docker-compose|kustomization|\.tf$|Chart\.yaml"

          FOUND_ISSUES=false
          for pattern in "${DISALLOWED_PATTERNS[@]}"; do
            MATCHES=$(grep -rnE "$pattern" \
              --include="*.html" --include="*.tsx" --include="*.ts" --include="*.md" \
              $EXCLUDE_PATTERNS apps/ services/ docs/ packages/i18n/ 2>/dev/null \
              | grep -vE "$WHITELIST_FILES" || true)
            if [ -n "$MATCHES" ]; then
              echo "::warning::Found disallowed branding pattern '$pattern'"
              echo "Matches found:"
              echo "$MATCHES"
              FOUND_ISSUES=true
            fi
          done

          if [ "$FOUND_ISSUES" = true ]; then
            echo "::error::Branding consistency issues found"
            exit 1
          fi
          echo "Branding consistency check passed!"

      - name: Type check API service
        run: cd services/api && pnpm typecheck
        continue-on-error: true

      - name: Lint codebase
        run: pnpm lint
        continue-on-error: true

  # ==========================================================================
  # STAGE 3: UNIT & INTEGRATION TESTS
  # ==========================================================================
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_tests == 'true'

    strategy:
      fail-fast: false
      matrix:
        include:
          - name: API
            path: services/api
            generate_prisma: true
          - name: Notification
            path: services/notification-service
            generate_prisma: true
          - name: Web
            path: apps/web
            generate_prisma: false

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Restore pnpm cache
        uses: actions/cache@v4
        with:
          path: ~/.local/share/pnpm/store
          key: ${{ needs.setup.outputs.cache-key }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Generate Prisma client
        if: matrix.generate_prisma
        run: cd ${{ matrix.path }} && pnpm db:generate
        continue-on-error: true

      - name: Run unit tests
        run: cd ${{ matrix.path }} && pnpm test
        env:
          NODE_ENV: test
          JWT_SECRET: ${{ secrets.TEST_JWT_SECRET }}
        continue-on-error: true

      - name: Upload coverage
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-${{ matrix.name }}
          path: ${{ matrix.path }}/coverage/
          if-no-files-found: ignore

  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_tests == 'true'
    # SECURITY FIX: Security tests MUST block deployment - stabilized as of 2026-01-09

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Generate Prisma client
        run: cd services/api && pnpm db:generate

      - name: Run security tests
        run: cd services/api && pnpm test -- tests/security/ --reporter=verbose
        env:
          NODE_ENV: test
          JWT_SECRET: ${{ secrets.TEST_JWT_SECRET }}

  # ==========================================================================
  # STAGE 4: SECURITY SCANNING
  # ==========================================================================
  dependency-audit:
    name: Dependency Audit
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_security == 'true'
    # SECURITY NOTE: Dependency vulnerabilities reported for review
    # Non-blocking - many vulnerabilities are in dev dependencies or have no fix available
    continue-on-error: true

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Run pnpm audit
        # Report vulnerabilities but don't block pipeline
        run: pnpm audit --audit-level=critical || true

  sast:
    name: SAST Analysis
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_security == 'true'
    # SECURITY NOTE: Semgrep findings are uploaded to GitHub Security tab for review
    # Non-blocking to allow pipeline to continue - findings should be reviewed separately

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Run Semgrep
        id: semgrep
        uses: returntocorp/semgrep-action@v1
        with:
          config: >-
            p/security-audit
            p/typescript
            p/nodejs
            p/owasp-top-ten
        continue-on-error: true
        env:
          SEMGREP_RULES: p/security-audit p/typescript p/nodejs p/owasp-top-ten

      - name: Generate SARIF output
        if: always()
        run: |
          pip install semgrep
          semgrep --config p/security-audit --config p/typescript --config p/nodejs --config p/owasp-top-ten --sarif --output semgrep.sarif . || true
        continue-on-error: true

      - name: Upload SARIF results
        uses: github/codeql-action/upload-sarif@v4
        if: always()
        with:
          sarif_file: semgrep.sarif
          category: semgrep
        continue-on-error: true

  secret-scan:
    name: Secret Scanning
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_security == 'true'
    # SECURITY NOTE: Gitleaks findings reported to GitHub Security tab
    # Non-blocking - known findings can be addressed or added to .gitleaksignore
    continue-on-error: true

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Run Gitleaks
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITLEAKS_ENABLE_UPLOAD_ARTIFACT: true
        continue-on-error: true

  codeql:
    name: CodeQL Analysis
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_security == 'true'
    permissions:
      security-events: write
      actions: read
      contents: read

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Initialize CodeQL
        uses: github/codeql-action/init@v4
        with:
          languages: javascript-typescript
          queries: security-extended,security-and-quality

      - name: Autobuild
        uses: github/codeql-action/autobuild@v4

      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v4
        with:
          category: "codeql-javascript"

  iac-scan:
    name: IaC Security Scan
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_security == 'true'
    # SECURITY NOTE: IaC findings uploaded to GitHub Security tab for review
    # Non-blocking to allow pipeline to continue - findings addressed separately
    continue-on-error: true

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Run Trivy IaC scanner
        uses: aquasecurity/trivy-action@0.30.0
        with:
          scan-type: "config"
          scan-ref: "./infrastructure"
          format: "sarif"
          output: "trivy-iac.sarif"
          severity: "CRITICAL,HIGH"
          exit-code: "0"
          trivyignores: ".trivyignore"
        continue-on-error: true

      - name: Upload Trivy IaC results
        uses: github/codeql-action/upload-sarif@v4
        if: always() && hashFiles('trivy-iac.sarif') != ''
        with:
          sarif_file: "trivy-iac.sarif"
          category: "trivy-iac"
        continue-on-error: true

  # ==========================================================================
  # STAGE 5: AWS PROVIDER VERIFICATION
  # ==========================================================================
  aws-provider-check:
    name: AWS Provider Verification
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_terraform == 'true'

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Verify AWS-only infrastructure
        run: |
          echo "Scanning for Azure contamination..."
          FAILED=0

          # Check for azurerm provider (excluding comments that document the policy)
          if grep -rE "^\s*provider\s+\"azurerm\"" infrastructure/terraform-aws/ --include="*.tf" 2>/dev/null; then
            echo "::error::Azure 'azurerm' provider block detected!"
            FAILED=1
          fi

          # Check for Azure resource types
          if grep -rE "^\s*resource\s+\"azurerm_" infrastructure/terraform-aws/ --include="*.tf" 2>/dev/null; then
            echo "::error::Azure resource types (azurerm_*) detected!"
            FAILED=1
          fi

          if [ $FAILED -eq 1 ]; then
            echo "::error::Azure contamination detected. This is an AWS-only deployment."
            exit 1
          fi

          echo "AWS-only verification passed"

      - name: Verify AWS provider exists
        run: |
          if ! grep -r "hashicorp/aws" infrastructure/terraform-aws/ --include="*.tf" 2>/dev/null; then
            echo "::error::AWS provider not found!"
            exit 1
          fi
          echo "AWS provider correctly configured"

  # ==========================================================================
  # STAGE 6: TERRAFORM VALIDATION & PLAN
  # ==========================================================================
  terraform-validate:
    name: Terraform Validate
    runs-on: ubuntu-latest
    needs: [setup, aws-provider-check]
    if: needs.setup.outputs.should_run_terraform == 'true'

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Terraform Format Check
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: terraform fmt -check -recursive
        continue-on-error: true

      - name: Terraform Init
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: terraform init -backend=false

      - name: Terraform Validate
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: terraform validate

  terraform-plan:
    name: Terraform Plan
    runs-on: ubuntu-latest
    needs: [setup, terraform-validate]
    if: needs.setup.outputs.should_run_terraform == 'true'
    environment: ${{ needs.setup.outputs.target_environment != 'none' && needs.setup.outputs.target_environment || 'dev' }}

    outputs:
      plan_has_changes: ${{ steps.plan.outputs.has_changes }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}
          terraform_wrapper: false

      - name: Terraform Init
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: |
          ENV="${{ needs.setup.outputs.target_environment }}"
          [ "$ENV" == "none" ] && ENV="dev"

          terraform init \
            -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
            -backend-config="key=env/${ENV}/terraform.tfstate" \
            -backend-config="region=${{ env.AWS_REGION }}" \
            -backend-config="dynamodb_table=${{ secrets.TF_LOCK_TABLE }}"

      - name: Terraform Plan
        id: plan
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: |
          ENV="${{ needs.setup.outputs.target_environment }}"
          [ "$ENV" == "none" ] && ENV="dev"

          terraform plan \
            -var-file=environments/${ENV}.tfvars \
            -out=tfplan \
            -detailed-exitcode \
            -no-color 2>&1 | tee plan-output.txt

          EXITCODE=${PIPESTATUS[0]}
          if [ $EXITCODE -eq 2 ]; then
            echo "has_changes=true" >> $GITHUB_OUTPUT
          else
            echo "has_changes=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload Plan
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan
          path: |
            ${{ env.TF_WORKING_DIR }}/tfplan
            ${{ env.TF_WORKING_DIR }}/plan-output.txt
          retention-days: 7

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let planOutput = 'Plan output not available';
            try {
              planOutput = fs.readFileSync('${{ env.TF_WORKING_DIR }}/plan-output.txt', 'utf8');
              if (planOutput.length > 60000) {
                planOutput = planOutput.substring(0, 60000) + '\n\n... (truncated)';
              }
            } catch (e) {}

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Terraform Plan\n\n\`\`\`\n${planOutput}\n\`\`\``
            });

  # ==========================================================================
  # STAGE 7: BUILD DOCKER IMAGES
  # ==========================================================================
  build-images:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [setup, unit-tests, security-tests, code-quality]
    if: |
      needs.setup.outputs.should_run_deploy == 'true' &&
      github.event.inputs.dry_run != 'true'

    strategy:
      fail-fast: false
      matrix:
        service:
          # Core API
          - name: api
            context: ./services/api
            dockerfile: ./services/api/Dockerfile
          # Frontend Apps
          - name: web-app
            context: .
            dockerfile: ./Dockerfile.web.pnpm
          - name: admin-portal
            context: .
            dockerfile: ./docker/Dockerfile.app
            build-args: SERVICE_PATH=apps/admin
          - name: provider-portal
            context: .
            dockerfile: ./docker/Dockerfile.app
            build-args: SERVICE_PATH=apps/provider-portal

          - name: kiosk
            context: .
            dockerfile: ./docker/Dockerfile.app
            build-args: SERVICE_PATH=apps/kiosk
          # Healthcare Services
          - name: api-gateway
            context: ./services/api-gateway
            dockerfile: ./services/api-gateway/Dockerfile
          - name: auth-service
            context: ./services/auth-service
            dockerfile: ./services/auth-service/Dockerfile
          - name: notification-service
            context: ./services/notification-service
            dockerfile: ./services/notification-service/Dockerfile
          - name: telehealth-service
            context: ./services/telehealth-service
            dockerfile: ./services/telehealth-service/Dockerfile
          - name: mental-health-service
            context: ./services/mental-health-service
            dockerfile: ./services/mental-health-service/Dockerfile
          - name: chronic-care-service
            context: ./services/chronic-care-service
            dockerfile: ./services/chronic-care-service/Dockerfile
          - name: pharmacy-service
            context: ./services/pharmacy-service
            dockerfile: ./services/pharmacy-service/Dockerfile
          - name: laboratory-service
            context: ./services/laboratory-service
            dockerfile: ./services/laboratory-service/Dockerfile
          - name: imaging-service
            context: ./services/imaging-service
            dockerfile: ./services/imaging-service/Dockerfile
          - name: clinical-trials-service
            context: ./services/clinical-trials-service
            dockerfile: ./services/clinical-trials-service/Dockerfile
          - name: interoperability-service
            context: ./services/interoperability-service
            dockerfile: ./services/interoperability-service/Dockerfile
          - name: price-transparency-service
            context: ./services/price-transparency-service
            dockerfile: ./services/price-transparency-service/Dockerfile
          - name: population-health-service
            context: ./services/population-health-service
            dockerfile: ./services/population-health-service/Dockerfile
          - name: home-health-service
            context: ./services/home-health-service
            dockerfile: ./services/home-health-service/Dockerfile
          - name: denial-management-service
            context: ./services/denial-management-service
            dockerfile: ./services/denial-management-service/Dockerfile
          - name: vendor-risk-service
            context: ./services/vendor-risk-service
            dockerfile: ./services/vendor-risk-service/Dockerfile
          # Note: Mobile app (React Native) doesn't have a Dockerfile - runs on iOS/Android

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push ${{ matrix.service.name }}
        uses: docker/build-push-action@v6
        with:
          context: ${{ matrix.service.context }}
          file: ${{ matrix.service.dockerfile }}
          push: true
          # SECURITY FIX: Only push immutable commit SHA tag - no mutable :latest
          # This enforces container immutability and prevents supply chain attacks
          tags: |
            ${{ steps.login-ecr.outputs.registry }}/unified-health-prod/${{ matrix.service.name }}:${{ needs.setup.outputs.commit_sha }}
          build-args: ${{ matrix.service.build-args }}
          cache-from: type=gha,scope=${{ matrix.service.name }}
          cache-to: type=gha,scope=${{ matrix.service.name }},mode=max

  # ==========================================================================
  # STAGE 8: CONTAINER SECURITY SCAN
  # ==========================================================================
  container-scan:
    name: Container Security Scan
    runs-on: ubuntu-latest
    # SECURITY NOTE: Scans images and uploads findings to GitHub Security tab
    # Non-blocking - findings should be reviewed and addressed separately
    needs: [setup, build-images]
    if: needs.build-images.result == 'success'
    continue-on-error: true

    strategy:
      fail-fast: false
      matrix:
        service:
          - api
          - web-app
          - admin-portal
          - provider-portal
          - kiosk
          - api-gateway
          - auth-service
          - notification-service
          - telehealth-service
          - mental-health-service
          - chronic-care-service
          - pharmacy-service
          - laboratory-service
          - imaging-service
          - clinical-trials-service
          - interoperability-service
          - price-transparency-service
          - population-health-service
          - home-health-service
          - denial-management-service
          - vendor-risk-service

    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
        continue-on-error: true

      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2
        continue-on-error: true

      - name: Run Trivy vulnerability scanner
        # SECURITY NOTE: Scans for CRITICAL/HIGH vulnerabilities
        # Results uploaded to GitHub Security tab for review
        uses: aquasecurity/trivy-action@0.30.0
        with:
          image-ref: "${{ secrets.ECR_REGISTRY }}/unified-health-prod/${{ matrix.service }}:${{ needs.setup.outputs.commit_sha }}"
          format: "sarif"
          output: "trivy-${{ matrix.service }}.sarif"
          severity: "CRITICAL,HIGH"
          exit-code: "0"
        continue-on-error: true

      - name: Upload Trivy results
        uses: github/codeql-action/upload-sarif@v4
        if: always()
        with:
          sarif_file: "trivy-${{ matrix.service }}.sarif"
          category: "trivy-${{ matrix.service }}"
        continue-on-error: true

  # ==========================================================================
  # STAGE 9: DEPLOY TO ENVIRONMENT
  # ==========================================================================
  deploy-dev:
    name: Deploy to Dev
    runs-on: ubuntu-latest
    needs: [setup, build-images, terraform-plan]
    # Only deploy if build succeeded - credentials checked at step level
    if: |
      needs.setup.outputs.should_run_deploy == 'true' &&
      needs.setup.outputs.target_environment == 'dev' &&
      needs.build-images.result == 'success'
    environment:
      name: dev
      url: https://dev.theunifiedhealth.com
    continue-on-error: true

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        id: aws-creds
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN_DEV }}
          aws-region: ${{ env.AWS_REGION }}
        continue-on-error: true

      - name: Login to Amazon ECR
        if: steps.aws-creds.outcome == 'success'
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Deploy to ECS Fargate
        if: steps.aws-creds.outcome == 'success'
        run: |
          CLUSTER="unified-health-dev-cluster"
          COMMIT_SHA="${{ needs.setup.outputs.commit_sha }}"
          ECR_REGISTRY="${{ secrets.ECR_REGISTRY }}"
          SERVICES="api,web-app"

          echo "Deploying to ECS cluster: $CLUSTER"

          IFS=',' read -ra SERVICE_ARRAY <<< "$SERVICES"
          for SERVICE in "${SERVICE_ARRAY[@]}"; do
            echo "Deploying service: $SERVICE"

            TASK_DEF=$(aws ecs describe-services \
              --cluster "$CLUSTER" \
              --services "$SERVICE" \
              --query 'services[0].taskDefinition' \
              --output text 2>/dev/null || echo "")

            if [ -z "$TASK_DEF" ] || [ "$TASK_DEF" == "None" ]; then
              echo "Service $SERVICE not found, skipping..."
              continue
            fi

            TASK_DEF_JSON=$(aws ecs describe-task-definition \
              --task-definition "$TASK_DEF" \
              --query 'taskDefinition')

            NEW_IMAGE="${ECR_REGISTRY}/unified-health-prod/${SERVICE}:${COMMIT_SHA}"

            NEW_TASK_DEF=$(echo "$TASK_DEF_JSON" | jq \
              --arg IMAGE "$NEW_IMAGE" \
              --arg SERVICE "$SERVICE" \
              '.containerDefinitions = [.containerDefinitions[] | if .name == $SERVICE then .image = $IMAGE else . end]' | \
              jq 'del(.taskDefinitionArn, .revision, .status, .requiresAttributes, .compatibilities, .registeredAt, .registeredBy)')

            NEW_TASK_DEF_ARN=$(aws ecs register-task-definition \
              --cli-input-json "$NEW_TASK_DEF" \
              --query 'taskDefinition.taskDefinitionArn' \
              --output text)

            aws ecs update-service \
              --cluster "$CLUSTER" \
              --service "$SERVICE" \
              --task-definition "$NEW_TASK_DEF_ARN" \
              --force-new-deployment \
              --output text > /dev/null

            echo "Deployed $SERVICE"
          done

      - name: Verify deployment
        if: steps.aws-creds.outcome == 'success'
        run: |
          CLUSTER="unified-health-dev-cluster"
          aws ecs wait services-stable \
            --cluster "$CLUSTER" \
            --services api web-app \
            --region ${{ env.AWS_REGION }} || true
          echo "Dev deployment verified"

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [setup, build-images, terraform-plan, deploy-dev]
    # Auto-deploy to staging after successful dev deployment (push to main)
    # OR manually triggered targeting staging environment
    # Staging does NOT require manual approval - auto-deploys after CI passes
    if: |
      needs.build-images.result == 'success' &&
      (
        (needs.deploy-dev.result == 'success' && needs.setup.outputs.target_environment == 'dev') ||
        (needs.setup.outputs.should_run_deploy == 'true' && needs.setup.outputs.target_environment == 'staging')
      )
    environment:
      name: staging
      url: https://staging.theunifiedhealth.com
    continue-on-error: true

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        id: aws-creds
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN_STAGING }}
          aws-region: ${{ env.AWS_REGION }}
        continue-on-error: true

      - name: Login to Amazon ECR
        if: steps.aws-creds.outcome == 'success'
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Deploy to ECS Fargate
        if: steps.aws-creds.outcome == 'success'
        run: |
          CLUSTER="unified-health-staging-cluster"
          COMMIT_SHA="${{ needs.setup.outputs.commit_sha }}"
          ECR_REGISTRY="${{ secrets.ECR_REGISTRY }}"
          SERVICES="api,web-app"

          echo "Deploying to ECS cluster: $CLUSTER"

          IFS=',' read -ra SERVICE_ARRAY <<< "$SERVICES"
          for SERVICE in "${SERVICE_ARRAY[@]}"; do
            echo "Deploying service: $SERVICE"

            TASK_DEF=$(aws ecs describe-services \
              --cluster "$CLUSTER" \
              --services "$SERVICE" \
              --query 'services[0].taskDefinition' \
              --output text 2>/dev/null || echo "")

            if [ -z "$TASK_DEF" ] || [ "$TASK_DEF" == "None" ]; then
              echo "Service $SERVICE not found, skipping..."
              continue
            fi

            TASK_DEF_JSON=$(aws ecs describe-task-definition \
              --task-definition "$TASK_DEF" \
              --query 'taskDefinition')

            NEW_IMAGE="${ECR_REGISTRY}/unified-health-prod/${SERVICE}:${COMMIT_SHA}"

            NEW_TASK_DEF=$(echo "$TASK_DEF_JSON" | jq \
              --arg IMAGE "$NEW_IMAGE" \
              --arg SERVICE "$SERVICE" \
              '.containerDefinitions = [.containerDefinitions[] | if .name == $SERVICE then .image = $IMAGE else . end]' | \
              jq 'del(.taskDefinitionArn, .revision, .status, .requiresAttributes, .compatibilities, .registeredAt, .registeredBy)')

            NEW_TASK_DEF_ARN=$(aws ecs register-task-definition \
              --cli-input-json "$NEW_TASK_DEF" \
              --query 'taskDefinition.taskDefinitionArn' \
              --output text)

            aws ecs update-service \
              --cluster "$CLUSTER" \
              --service "$SERVICE" \
              --task-definition "$NEW_TASK_DEF_ARN" \
              --force-new-deployment \
              --output text > /dev/null

            echo "Deployed $SERVICE"
          done

      - name: Verify deployment
        if: steps.aws-creds.outcome == 'success'
        run: |
          CLUSTER="unified-health-staging-cluster"
          aws ecs wait services-stable \
            --cluster "$CLUSTER" \
            --services api web-app \
            --region ${{ env.AWS_REGION }}
          echo "Staging deployment verified"

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [setup, build-images, terraform-plan, deploy-staging]
    # Production deployment REQUIRES MANUAL APPROVAL via GitHub environment protection rules
    # This job will wait for approval when the 'production' environment has required reviewers configured
    # Only runs when explicitly targeting production (scheduled or manual dispatch)
    if: |
      needs.setup.outputs.should_run_deploy == 'true' &&
      needs.setup.outputs.target_environment == 'production' &&
      needs.build-images.result == 'success' &&
      github.event.inputs.dry_run != 'true'
    environment:
      name: production
      url: https://theunifiedhealth.com
    continue-on-error: true

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        id: aws-creds
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN_PROD }}
          aws-region: ${{ env.AWS_REGION }}
        continue-on-error: true

      - name: Login to Amazon ECR
        if: steps.aws-creds.outcome == 'success'
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Deploy to ECS Fargate
        if: steps.aws-creds.outcome == 'success'
        run: |
          CLUSTER="unified-health-prod-cluster"
          COMMIT_SHA="${{ needs.setup.outputs.commit_sha }}"
          ECR_REGISTRY="${{ secrets.ECR_REGISTRY }}"
          SERVICES="api,web-app,api-gateway"

          echo "Deploying to ECS cluster: $CLUSTER"

          IFS=',' read -ra SERVICE_ARRAY <<< "$SERVICES"
          for SERVICE in "${SERVICE_ARRAY[@]}"; do
            echo "Deploying service: $SERVICE"

            TASK_DEF=$(aws ecs describe-services \
              --cluster "$CLUSTER" \
              --services "$SERVICE" \
              --query 'services[0].taskDefinition' \
              --output text 2>/dev/null || echo "")

            if [ -z "$TASK_DEF" ] || [ "$TASK_DEF" == "None" ]; then
              echo "Service $SERVICE not found, skipping..."
              continue
            fi

            TASK_DEF_JSON=$(aws ecs describe-task-definition \
              --task-definition "$TASK_DEF" \
              --query 'taskDefinition')

            NEW_IMAGE="${ECR_REGISTRY}/unified-health-prod/${SERVICE}:${COMMIT_SHA}"

            NEW_TASK_DEF=$(echo "$TASK_DEF_JSON" | jq \
              --arg IMAGE "$NEW_IMAGE" \
              --arg SERVICE "$SERVICE" \
              '.containerDefinitions = [.containerDefinitions[] | if .name == $SERVICE then .image = $IMAGE else . end]' | \
              jq 'del(.taskDefinitionArn, .revision, .status, .requiresAttributes, .compatibilities, .registeredAt, .registeredBy)')

            NEW_TASK_DEF_ARN=$(aws ecs register-task-definition \
              --cli-input-json "$NEW_TASK_DEF" \
              --query 'taskDefinition.taskDefinitionArn' \
              --output text)

            aws ecs update-service \
              --cluster "$CLUSTER" \
              --service "$SERVICE" \
              --task-definition "$NEW_TASK_DEF_ARN" \
              --force-new-deployment \
              --output text > /dev/null

            echo "Deployed $SERVICE"
          done

      - name: Verify deployment
        if: steps.aws-creds.outcome == 'success'
        run: |
          CLUSTER="unified-health-prod-cluster"
          aws ecs wait services-stable \
            --cluster "$CLUSTER" \
            --services api web-app api-gateway \
            --region ${{ env.AWS_REGION }}

      - name: Health check
        if: steps.aws-creds.outcome == 'success'
        run: |
          CLUSTER="unified-health-prod-cluster"
          for SERVICE in api web-app api-gateway; do
            RUNNING=$(aws ecs describe-services \
              --cluster "$CLUSTER" \
              --services "$SERVICE" \
              --query 'services[0].runningCount' \
              --output text)
            DESIRED=$(aws ecs describe-services \
              --cluster "$CLUSTER" \
              --services "$SERVICE" \
              --query 'services[0].desiredCount' \
              --output text)
            echo "$SERVICE: $RUNNING/$DESIRED tasks running"
          done
          echo "Production deployment verified"

  # ==========================================================================
  # STAGE 10: TERRAFORM APPLY
  # ==========================================================================
  # Terraform Apply runs after Plan succeeds and security checks pass.
  # - Dev/Staging: Auto-apply when plan has changes (no manual approval)
  # - Production: Requires manual approval via environment protection rules
  # ==========================================================================

  terraform-apply-dev:
    name: Terraform Apply (Dev)
    runs-on: ubuntu-latest
    needs: [setup, terraform-plan, security-tests, sast, iac-scan]
    # Dev auto-applies when:
    # 1. Terraform is enabled and targeting dev environment
    # 2. Plan succeeded with changes
    # 3. Security tests did not fail (skipped is OK)
    if: |
      always() &&
      needs.setup.outputs.should_run_terraform == 'true' &&
      needs.setup.outputs.target_environment == 'dev' &&
      needs.terraform-plan.result == 'success' &&
      needs.terraform-plan.outputs.plan_has_changes == 'true' &&
      needs.security-tests.result != 'failure'
    environment:
      name: dev
      url: https://dev.theunifiedhealth.com

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN_DEV }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Download Plan
        uses: actions/download-artifact@v4
        with:
          name: terraform-plan
          path: ${{ env.TF_WORKING_DIR }}

      - name: Terraform Init
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: |
          terraform init \
            -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
            -backend-config="key=env/dev/terraform.tfstate" \
            -backend-config="region=${{ env.AWS_REGION }}" \
            -backend-config="dynamodb_table=${{ secrets.TF_LOCK_TABLE }}"

      - name: Terraform Apply
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: terraform apply -auto-approve tfplan

  terraform-apply-staging:
    name: Terraform Apply (Staging)
    runs-on: ubuntu-latest
    needs: [setup, terraform-plan, security-tests, sast, iac-scan]
    # Staging auto-applies when:
    # 1. Terraform is enabled and targeting staging environment
    # 2. Plan succeeded with changes
    # 3. Security tests did not fail (skipped is OK)
    if: |
      always() &&
      needs.setup.outputs.should_run_terraform == 'true' &&
      needs.setup.outputs.target_environment == 'staging' &&
      needs.terraform-plan.result == 'success' &&
      needs.terraform-plan.outputs.plan_has_changes == 'true' &&
      needs.security-tests.result != 'failure'
    environment:
      name: staging
      url: https://staging.theunifiedhealth.com

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN_STAGING }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Download Plan
        uses: actions/download-artifact@v4
        with:
          name: terraform-plan
          path: ${{ env.TF_WORKING_DIR }}

      - name: Terraform Init
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: |
          terraform init \
            -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
            -backend-config="key=env/staging/terraform.tfstate" \
            -backend-config="region=${{ env.AWS_REGION }}" \
            -backend-config="dynamodb_table=${{ secrets.TF_LOCK_TABLE }}"

      - name: Terraform Apply
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: terraform apply -auto-approve tfplan

  terraform-apply-production:
    name: Terraform Apply (Production)
    runs-on: ubuntu-latest
    needs: [setup, terraform-plan, security-tests, sast, iac-scan]
    # Production requires MANUAL APPROVAL via GitHub environment protection rules.
    # The 'production-infrastructure' environment should have required reviewers configured.
    # Apply runs when:
    # 1. Terraform is enabled and targeting production environment
    # 2. Plan succeeded with changes
    # 3. Security tests did not fail
    # 4. Explicitly requested via workflow_dispatch with terraform_action=apply
    #    OR scheduled deployment window (Wednesday 3am UTC)
    if: |
      always() &&
      needs.setup.outputs.should_run_terraform == 'true' &&
      needs.setup.outputs.target_environment == 'production' &&
      needs.terraform-plan.result == 'success' &&
      needs.terraform-plan.outputs.plan_has_changes == 'true' &&
      needs.security-tests.result != 'failure' &&
      (github.event.inputs.terraform_action == 'apply' || github.event_name == 'schedule')
    environment:
      name: production-infrastructure
      url: https://console.aws.amazon.com

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN_PROD }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Download Plan
        uses: actions/download-artifact@v4
        with:
          name: terraform-plan
          path: ${{ env.TF_WORKING_DIR }}

      - name: Terraform Init
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: |
          terraform init \
            -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
            -backend-config="key=env/production/terraform.tfstate" \
            -backend-config="region=${{ env.AWS_REGION }}" \
            -backend-config="dynamodb_table=${{ secrets.TF_LOCK_TABLE }}"

      - name: Terraform Apply
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: terraform apply -auto-approve tfplan

  # ==========================================================================
  # STAGE 11: LIGHTHOUSE PERFORMANCE AUDIT
  # ==========================================================================
  # Runs automatically on:
  # - Pull requests (for performance regression detection)
  # - Push to main branch (for continuous performance monitoring)
  # - Manual workflow dispatch with run_lighthouse=true
  # - PRs with the 'lighthouse' label
  # ==========================================================================
  lighthouse:
    name: Lighthouse Audit
    runs-on: ubuntu-latest
    needs: [setup, code-quality]
    if: |
      always() &&
      needs.setup.result == 'success' &&
      (
        needs.setup.outputs.should_run_lighthouse == 'true' ||
        (github.event_name == 'pull_request' && contains(github.event.pull_request.labels.*.name, 'lighthouse'))
      )

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Restore pnpm cache
        uses: actions/cache@v4
        with:
          path: ~/.local/share/pnpm/store
          key: ${{ needs.setup.outputs.cache-key }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build web application
        run: pnpm --filter @unified-health/web build
        env:
          NODE_ENV: production
          NEXT_PUBLIC_API_URL: http://localhost:4000

      - name: Install Chrome
        uses: browser-actions/setup-chrome@v1.7.2
        with:
          chrome-version: stable

      - name: Run Lighthouse CI
        run: |
          npm install -g @lhci/cli@0.13.x
          lhci autorun --config=lighthouserc.js || echo "Lighthouse completed with warnings"
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}

      - name: Upload Lighthouse reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: lighthouse-reports
          path: .lighthouseci
          retention-days: 30

      - name: Comment PR with Lighthouse results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            let summary = '## Lighthouse Performance Audit\n\n';

            try {
              const manifestPath = '.lighthouseci/manifest.json';
              if (fs.existsSync(manifestPath)) {
                const manifest = JSON.parse(fs.readFileSync(manifestPath, 'utf8'));
                summary += '| URL | Performance | Accessibility | Best Practices | SEO |\n';
                summary += '|-----|-------------|---------------|----------------|-----|\n';

                for (const entry of manifest) {
                  if (entry.summary) {
                    const perf = Math.round((entry.summary.performance || 0) * 100);
                    const a11y = Math.round((entry.summary.accessibility || 0) * 100);
                    const bp = Math.round((entry.summary['best-practices'] || 0) * 100);
                    const seo = Math.round((entry.summary.seo || 0) * 100);

                    const perfEmoji = perf >= 90 ? ':green_circle:' : perf >= 50 ? ':yellow_circle:' : ':red_circle:';
                    const a11yEmoji = a11y >= 90 ? ':green_circle:' : a11y >= 50 ? ':yellow_circle:' : ':red_circle:';
                    const bpEmoji = bp >= 90 ? ':green_circle:' : bp >= 50 ? ':yellow_circle:' : ':red_circle:';
                    const seoEmoji = seo >= 90 ? ':green_circle:' : seo >= 50 ? ':yellow_circle:' : ':red_circle:';

                    summary += `| ${entry.url} | ${perfEmoji} ${perf} | ${a11yEmoji} ${a11y} | ${bpEmoji} ${bp} | ${seoEmoji} ${seo} |\n`;
                  }
                }
              } else {
                summary += '_Lighthouse results not available._\n';
              }
            } catch (e) {
              summary += `_Error reading Lighthouse results: ${e.message}_\n`;
            }

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

  # ==========================================================================
  # STAGE 12: SBOM GENERATION
  # ==========================================================================
  sbom:
    name: Generate SBOM
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_sbom == 'true'
    permissions:
      contents: write
      id-token: write
      security-events: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Determine version
        id: version
        run: |
          if [[ "${{ github.ref }}" == refs/tags/* ]]; then
            VERSION="${{ github.ref_name }}"
          else
            VERSION="dev-$(git rev-parse --short HEAD)"
          fi
          echo "version=${VERSION}" >> $GITHUB_OUTPUT
          echo "Generated version: ${VERSION}"

      - name: Install Syft
        uses: anchore/sbom-action/download-syft@v0

      - name: Generate SBOM (CycloneDX JSON format)
        run: |
          mkdir -p sbom-artifacts
          syft scan dir:. \
            --output cyclonedx-json=sbom-artifacts/sbom-cyclonedx-${{ steps.version.outputs.version }}.json \
            --name unified-health-platform \
            --version ${{ steps.version.outputs.version }}
          echo "CycloneDX SBOM generated successfully"

      - name: Generate SBOM (SPDX JSON format)
        run: |
          syft scan dir:. \
            --output spdx-json=sbom-artifacts/sbom-spdx-${{ steps.version.outputs.version }}.json \
            --name unified-health-platform \
            --version ${{ steps.version.outputs.version }}
          echo "SPDX SBOM generated successfully"

      - name: Generate SBOM (Table format for review)
        run: |
          syft scan dir:. \
            --output table=sbom-artifacts/sbom-summary-${{ steps.version.outputs.version }}.txt \
            --name unified-health-platform \
            --version ${{ steps.version.outputs.version }}
          echo "SBOM summary table generated"

      - name: Install Grype for vulnerability scanning
        uses: anchore/scan-action/download-grype@v4

      - name: Scan SBOM for vulnerabilities
        id: vuln-scan
        run: |
          grype sbom:sbom-artifacts/sbom-cyclonedx-${{ steps.version.outputs.version }}.json \
            --output sarif \
            --file sbom-artifacts/sbom-vulnerabilities.sarif || true
          grype sbom:sbom-artifacts/sbom-cyclonedx-${{ steps.version.outputs.version }}.json \
            --output table \
            --file sbom-artifacts/sbom-vulnerabilities-${{ steps.version.outputs.version }}.txt || true
          echo "Vulnerability scan completed"

      - name: Upload vulnerability results to GitHub Security
        uses: github/codeql-action/upload-sarif@v4
        if: always() && hashFiles('sbom-artifacts/sbom-vulnerabilities.sarif') != ''
        with:
          sarif_file: sbom-artifacts/sbom-vulnerabilities.sarif
          category: sbom-vulnerabilities
        continue-on-error: true

      - name: Generate SBOM metadata
        run: |
          cat > sbom-artifacts/sbom-metadata.json << EOF
          {
            "platform": "unified-health-platform",
            "version": "${{ steps.version.outputs.version }}",
            "commit": "${{ github.sha }}",
            "branch": "${{ github.ref_name }}",
            "generated_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "generator": "syft",
            "formats": ["cyclonedx-json", "spdx-json", "table"],
            "workflow_run_id": "${{ github.run_id }}",
            "workflow_run_url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          }
          EOF
          echo "SBOM metadata generated"

      - name: Upload SBOM artifacts
        uses: actions/upload-artifact@v4
        with:
          name: sbom-${{ steps.version.outputs.version }}
          path: sbom-artifacts/
          retention-days: 90

      - name: Attach to release
        if: github.event_name == 'release'
        uses: softprops/action-gh-release@v2
        with:
          files: |
            sbom-artifacts/sbom-cyclonedx-*.json
            sbom-artifacts/sbom-spdx-*.json
            sbom-artifacts/sbom-metadata.json
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: SBOM Summary
        run: |
          echo "## SBOM Generation Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Version:** ${{ steps.version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Generated Files" >> $GITHUB_STEP_SUMMARY
          echo "- CycloneDX JSON: \`sbom-cyclonedx-${{ steps.version.outputs.version }}.json\`" >> $GITHUB_STEP_SUMMARY
          echo "- SPDX JSON: \`sbom-spdx-${{ steps.version.outputs.version }}.json\`" >> $GITHUB_STEP_SUMMARY
          echo "- Summary Table: \`sbom-summary-${{ steps.version.outputs.version }}.txt\`" >> $GITHUB_STEP_SUMMARY
          echo "- Vulnerability Report: \`sbom-vulnerabilities-${{ steps.version.outputs.version }}.txt\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Package Summary" >> $GITHUB_STEP_SUMMARY
          if [ -f "sbom-artifacts/sbom-summary-${{ steps.version.outputs.version }}.txt" ]; then
            TOTAL_PKGS=$(wc -l < "sbom-artifacts/sbom-summary-${{ steps.version.outputs.version }}.txt" || echo "0")
            echo "Total packages found: $TOTAL_PKGS" >> $GITHUB_STEP_SUMMARY
          fi

  # ==========================================================================
  # STAGE 13: DRIFT DETECTION
  # ==========================================================================
  drift-check:
    name: Infrastructure Drift Check
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_run_drift == 'true'

    strategy:
      matrix:
        environment: [dev, staging, prod]

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Terraform Init
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: |
          terraform init \
            -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
            -backend-config="key=env/${{ matrix.environment }}/terraform.tfstate" \
            -backend-config="region=${{ env.AWS_REGION }}" \
            -backend-config="dynamodb_table=${{ secrets.TF_LOCK_TABLE }}"

      - name: Terraform Plan (Drift Detection)
        id: plan
        working-directory: ${{ env.TF_WORKING_DIR }}
        run: |
          terraform plan \
            -var-file=environments/${{ matrix.environment }}.tfvars \
            -detailed-exitcode \
            -no-color 2>&1 | tee drift-output.txt; EXITCODE=${PIPESTATUS[0]}
          echo "exitcode=$EXITCODE" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Check for Drift
        if: steps.plan.outputs.exitcode == '2'
        run: |
          echo "::warning::Drift detected in ${{ matrix.environment }} environment!"

      - name: Create Issue for Drift
        if: steps.plan.outputs.exitcode == '2' && matrix.environment == 'prod'
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `[DRIFT] Infrastructure drift detected in ${{ matrix.environment }}`,
              body: `## Infrastructure Drift Detected\n\n**Environment:** ${{ matrix.environment }}\n**Detected:** ${new Date().toISOString()}\n\nPlease review and remediate.`,
              labels: ['drift', '${{ matrix.environment }}', 'infrastructure']
            });

  # ==========================================================================
  # STAGE 14: ROLLBACK (On Failure)
  # ==========================================================================
  rollback:
    name: Rollback on Failure
    runs-on: ubuntu-latest
    needs: [setup, deploy-production]
    if: failure() && needs.deploy-production.result == 'failure'

    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN_PROD }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Rollback ECS services
        run: |
          CLUSTER="unified-health-prod-cluster"
          SERVICES="api,web-app,api-gateway"

          echo "::warning::Initiating ECS rollback due to deployment failure"

          IFS=',' read -ra SERVICE_ARRAY <<< "$SERVICES"
          for SERVICE in "${SERVICE_ARRAY[@]}"; do
            echo "Rolling back $SERVICE..."

            # Get current task definition ARN
            CURRENT_TASK=$(aws ecs describe-services \
              --cluster "$CLUSTER" \
              --services "$SERVICE" \
              --query 'services[0].taskDefinition' \
              --output text 2>/dev/null || echo "")

            if [ -z "$CURRENT_TASK" ] || [ "$CURRENT_TASK" == "None" ]; then
              echo "Service $SERVICE not found, skipping rollback"
              continue
            fi

            # Get previous task definition (current revision - 1)
            FAMILY=$(echo "$CURRENT_TASK" | sed 's/:.*$//' | sed 's/.*\///')
            CURRENT_REV=$(echo "$CURRENT_TASK" | sed 's/.*://')
            PREV_REV=$((CURRENT_REV - 1))

            if [ $PREV_REV -lt 1 ]; then
              echo "No previous revision for $SERVICE"
              continue
            fi

            PREV_TASK="${FAMILY}:${PREV_REV}"
            echo "Rolling back from revision $CURRENT_REV to $PREV_REV"

            # Update service to previous task definition
            aws ecs update-service \
              --cluster "$CLUSTER" \
              --service "$SERVICE" \
              --task-definition "$PREV_TASK" \
              --force-new-deployment \
              --output text > /dev/null

            echo "Rollback triggered for $SERVICE"
          done

      - name: Wait for rollback to complete
        run: |
          CLUSTER="unified-health-prod-cluster"
          aws ecs wait services-stable \
            --cluster "$CLUSTER" \
            --services api web-app api-gateway \
            --region ${{ env.AWS_REGION }} || true
          echo "Rollback completed"

  # ==========================================================================
  # STAGE 15: PIPELINE SUMMARY
  # ==========================================================================
  summary:
    name: Pipeline Summary
    runs-on: ubuntu-latest
    needs:
      - setup
      - code-quality
      - unit-tests
      - security-tests
      - dependency-audit
      - sast
      - secret-scan
      - terraform-validate
      - terraform-plan
      - terraform-apply-dev
      - terraform-apply-staging
      - terraform-apply-production
      - build-images
      - deploy-dev
      - deploy-staging
      - deploy-production
      - lighthouse
      - sbom
    if: always()

    steps:
      - name: Generate summary
        run: |
          echo "## Unified Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Stage | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Setup | ${{ needs.setup.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Code Quality | ${{ needs.code-quality.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Unit Tests | ${{ needs.unit-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Security Tests | ${{ needs.security-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Dependency Audit | ${{ needs.dependency-audit.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| SAST | ${{ needs.sast.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Secret Scan | ${{ needs.secret-scan.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Lighthouse Audit | ${{ needs.lighthouse.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| SBOM Generation | ${{ needs.sbom.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Terraform Validate | ${{ needs.terraform-validate.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Terraform Plan | ${{ needs.terraform-plan.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Terraform Apply (Dev) | ${{ needs.terraform-apply-dev.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Terraform Apply (Staging) | ${{ needs.terraform-apply-staging.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Terraform Apply (Production) | ${{ needs.terraform-apply-production.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Build Images | ${{ needs.build-images.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Deploy Dev | ${{ needs.deploy-dev.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Deploy Staging | ${{ needs.deploy-staging.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Deploy Production | ${{ needs.deploy-production.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ needs.setup.outputs.commit_sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Target Environment:** ${{ needs.setup.outputs.target_environment }}" >> $GITHUB_STEP_SUMMARY

      - name: Post PR comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const results = {
              'Code Quality': '${{ needs.code-quality.result }}',
              'Unit Tests': '${{ needs.unit-tests.result }}',
              'Security Tests': '${{ needs.security-tests.result }}',
              'SAST': '${{ needs.sast.result }}',
              'Lighthouse': '${{ needs.lighthouse.result }}',
              'Terraform': '${{ needs.terraform-plan.result }}'
            };

            let table = '| Check | Status |\n|-------|--------|\n';
            for (const [check, result] of Object.entries(results)) {
              const emoji = result === 'success' ? ':white_check_mark:' :
                           result === 'failure' ? ':x:' : ':warning:';
              table += `| ${check} | ${emoji} ${result} |\n`;
            }

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Unified Pipeline Results\n\n${table}`
            });
